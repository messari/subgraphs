{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "graph_id = \"QmYkEQD9MFq2tGcB7QX3Znn8H2FNrridwjd9CcKaFVNqJW\"\n",
    "url = f\"https://api.thegraph.com/subgraphs/id/{graph_id}\"\n",
    "\n",
    "\n",
    "PASS = \"PASS\"\n",
    "FAIL = \"FAIL\"\n",
    "MATCH_PERCENT_TOLERANCE = 0.00001 # Much be within 0.001% of eachother\n",
    "PAGE_LENGTH = 1000\n",
    "\n",
    "check_summary = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "def list_items_match(a: list, b: list) -> list:\n",
    "    exact_match = (a == b)\n",
    "    within_tolerance = abs(1 - a / b) < MATCH_PERCENT_TOLERANCE\n",
    "    return exact_match | within_tolerance \n",
    "    \n",
    "def perform_request(query, variables = {}):\n",
    "    res = requests.post(url, json={\"query\": query, \"variables\": variables})\n",
    "    return json.loads(res.text)[\"data\"]\n",
    "\n",
    "def perform_pagenation_request(pageable_query, key, varibales={}):\n",
    "    all_found = False\n",
    "    skip = 0\n",
    "    data = []\n",
    "\n",
    "    while(not all_found):\n",
    "        query_variables = varibales\n",
    "        query_variables[\"page_length\"] = PAGE_LENGTH\n",
    "        query_variables[\"skip\"] = skip\n",
    "\n",
    "        res = requests.post(url, json={\"query\": pageable_query, \"variables\": query_variables}) \n",
    "\n",
    "        new_data = json.loads(res.text)[\"data\"][key]\n",
    "        data += new_data\n",
    "\n",
    "        all_found = (len(new_data) != PAGE_LENGTH)\n",
    "        skip += PAGE_LENGTH\n",
    "    \n",
    "    return {key: data}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_accounts: 460, cumulative_users: 460, result: PASS\n"
     ]
    }
   ],
   "source": [
    "# Check total accounts equals protocol account\n",
    "accounts_query = \"\"\"query($skip: Int!, $page_length: Int!) {\n",
    "    accounts(first: $page_length, skip: $skip) {\n",
    "        id\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "protocol_query = \"\"\"query {\n",
    "    protocols {\n",
    "        cumulativeUniqueUsers\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "account_data = perform_pagenation_request(accounts_query, \"accounts\")\n",
    "protocol_data = perform_request(protocol_query)\n",
    "num_accounts = len(account_data[\"accounts\"])\n",
    "cumulative_users = protocol_data[\"protocols\"][0][\"cumulativeUniqueUsers\"]\n",
    "\n",
    "result = PASS if num_accounts == cumulative_users else FAIL \n",
    "\n",
    "print(f\"num_accounts: {num_accounts}, cumulative_users: {cumulative_users}, result: {result}\")\n",
    "\n",
    "check_summary[\"unique_user_check\"] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   market_sums  protocol_cumulatives result\n",
      "totalValueLockedUSD               3.397133e+08          3.397133e+08   PASS\n",
      "cumulativeSupplySideRevenueUSD    5.447125e+06          5.447125e+06   PASS\n",
      "cumulativeProtocolSideRevenueUSD  3.406500e+07          3.406500e+07   PASS\n",
      "cumulativeTotalRevenueUSD         3.951212e+07          3.951212e+07   PASS\n",
      "totalDepositBalanceUSD            3.310131e+08          3.310131e+08   PASS\n",
      "cumulativeDepositUSD              3.395354e+08          3.395354e+08   PASS\n",
      "totalBorrowBalanceUSD             3.066000e+08          3.066000e+08   PASS\n",
      "cumulativeBorrowUSD               3.298500e+08          3.298500e+08   PASS\n",
      "cumulativeLiquidateUSD            0.000000e+00          0.000000e+00   PASS\n"
     ]
    }
   ],
   "source": [
    "# Check cumulative for protocol match sum for pools\n",
    "\n",
    "query = \"\"\"query {\n",
    "    lendingProtocols {\n",
    "        totalValueLockedUSD\n",
    "        cumulativeSupplySideRevenueUSD\n",
    "        cumulativeProtocolSideRevenueUSD\n",
    "        cumulativeTotalRevenueUSD\n",
    "        totalDepositBalanceUSD\n",
    "        cumulativeDepositUSD\n",
    "        totalBorrowBalanceUSD\n",
    "        cumulativeBorrowUSD\n",
    "        cumulativeLiquidateUSD\n",
    "    }\n",
    "    markets {\n",
    "        totalValueLockedUSD\n",
    "        _cumulativeSupplySideRevenueUSD\n",
    "        _cumulativeProtocolSideRevenueUSD\n",
    "        _cumulativeTotalRevenueUSD\n",
    "        totalDepositBalanceUSD\n",
    "        cumulativeDepositUSD\n",
    "        totalBorrowBalanceUSD\n",
    "        cumulativeBorrowUSD\n",
    "        cumulativeLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "data = perform_request(query)\n",
    "protcol_data = data[\"lendingProtocols\"][0]\n",
    "market_data = data[\"markets\"]\n",
    "df = pd.DataFrame(market_data)\n",
    "df.rename(columns = {'_cumulativeSupplySideRevenueUSD':'cumulativeSupplySideRevenueUSD', '_cumulativeProtocolSideRevenueUSD':'cumulativeProtocolSideRevenueUSD', \"_cumulativeTotalRevenueUSD\": \"cumulativeTotalRevenueUSD\"}, inplace = True)\n",
    "df = df.apply(pd.to_numeric, errors='coerce') \n",
    "market_sums = df.sum(axis=0)\n",
    "\n",
    "compare_df = pd.DataFrame({\"market_sums\": market_sums, \"protocol_cumulatives\": protcol_data})\n",
    "compare_df = compare_df.apply(pd.to_numeric, errors='coerce') \n",
    "compare_df[\"result\"] = np.where(list_items_match(compare_df[\"market_sums\"], compare_df[\"protocol_cumulatives\"]), PASS, FAIL)\n",
    "print(compare_df)\n",
    "\n",
    "result = PASS if (compare_df[\"result\"].to_numpy() == PASS).all() else FAIL\n",
    "\n",
    "check_summary[\"protocol_cumulatives_match_check\"] = result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  snapshot_sums  protocol_cumulatives result\n",
      "cumulativeSupplySideRevenueUSD     2.063669e+08          5.447125e+06   FAIL\n",
      "cumulativeProtocolSideRevenueUSD   3.406500e+07          3.406500e+07   PASS\n",
      "cumulativeDepositUSD               3.395354e+08          3.395354e+08   PASS\n",
      "cumulativeBorrowUSD                3.298500e+08          3.298500e+08   PASS\n",
      "cumulativeLiquidateUSD             0.000000e+00          0.000000e+00   PASS\n"
     ]
    }
   ],
   "source": [
    "# Check financial snapshots add up to protocol_cumulatives\n",
    "\n",
    "snapshot_query = \"\"\"query($skip: Int!, $page_length: Int!) {\n",
    "    financialsDailySnapshots(first: $page_length, skip: $skip) {\n",
    "        dailySupplySideRevenueUSD\n",
    "        dailyProtocolSideRevenueUSD\n",
    "        dailyDepositUSD\n",
    "        dailyBorrowUSD\n",
    "        dailyLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "protocol_query = \"\"\"query {\n",
    "    lendingProtocols {\n",
    "        cumulativeSupplySideRevenueUSD\n",
    "        cumulativeProtocolSideRevenueUSD\n",
    "        cumulativeDepositUSD\n",
    "        cumulativeBorrowUSD\n",
    "        cumulativeLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "protocol_data = perform_request(protocol_query)[\"lendingProtocols\"][0]\n",
    "snapshot_data = perform_pagenation_request(snapshot_query, \"financialsDailySnapshots\")[\"financialsDailySnapshots\"]\n",
    "df = pd.DataFrame(snapshot_data)\n",
    "df = df.apply(pd.to_numeric, errors='coerce') \n",
    "df.rename(columns = {'dailySupplySideRevenueUSD':'cumulativeSupplySideRevenueUSD', 'dailyProtocolSideRevenueUSD':'cumulativeProtocolSideRevenueUSD', \"dailyDepositUSD\": \"cumulativeDepositUSD\", \"dailyBorrowUSD\": \"cumulativeBorrowUSD\", \"dailyLiquidateUSD\": \"cumulativeLiquidateUSD\"}, inplace = True)\n",
    "sums = df.sum(axis=0)\n",
    "\n",
    "compare_df = pd.DataFrame({\"snapshot_sums\": sums, \"protocol_cumulatives\": protocol_data})\n",
    "compare_df = compare_df.apply(pd.to_numeric, errors='coerce') \n",
    "compare_df[\"result\"] = np.where(list_items_match(compare_df[\"snapshot_sums\"], compare_df[\"protocol_cumulatives\"]), PASS, FAIL)\n",
    "print(compare_df)\n",
    "\n",
    "result = PASS if (compare_df[\"result\"].to_numpy() == PASS).all() else FAIL\n",
    "\n",
    "check_summary[\"financial_snapshots_check\"] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        market_data  hourly_snapshot_sums  \\\n",
      "cumulativeDepositUSD     21250090.0              21250090   \n",
      "cumulativeBorrowUSD      21250000.0              21250000   \n",
      "cumulativeLiquidateUSD          0.0                     0   \n",
      "\n",
      "                        daily_snapshot_sums result  \n",
      "cumulativeDepositUSD               21250090   PASS  \n",
      "cumulativeBorrowUSD                21250000   PASS  \n",
      "cumulativeLiquidateUSD                    0   PASS  \n"
     ]
    }
   ],
   "source": [
    "# Check market snapshots add up to market cumulatives\n",
    "\n",
    "market_query = \"\"\"query {\n",
    "    markets(first: 1) {\n",
    "        id\n",
    "        cumulativeDepositUSD\n",
    "        cumulativeBorrowUSD\n",
    "        cumulativeLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "hourly_snapshot_query = \"\"\"query($skip: Int!, $page_length: Int!, $market: String!) {\n",
    "    marketHourlySnapshots(first: $page_length, skip: $skip, where: {market: $market}) {\n",
    "        hourlyDepositUSD\n",
    "        hourlyBorrowUSD\n",
    "        hourlyLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "daily_snapshot_query = \"\"\"query($skip: Int!, $page_length: Int!, $market: String!) {\n",
    "    marketDailySnapshots(first: $page_length, skip: $skip, where: {market: $market}) {\n",
    "        dailyDepositUSD\n",
    "        dailyBorrowUSD\n",
    "        dailyLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "data = perform_request(query) \n",
    "market_data = perform_request(market_query)[\"markets\"][0]\n",
    "market_id = market_data[\"id\"]\n",
    "filtered_market_data = {\"cumulativeDepositUSD\": float(market_data[\"cumulativeDepositUSD\"]), \"cumulativeBorrowUSD\": float(market_data[\"cumulativeBorrowUSD\"]), \"cumulativeLiquidateUSD\": float(market_data[\"cumulativeLiquidateUSD\"])}\n",
    "\n",
    "query_variables = {\"market\": market_id}\n",
    "hourly_snapshot_data = perform_pagenation_request(hourly_snapshot_query, \"marketHourlySnapshots\", query_variables)[\"marketHourlySnapshots\"]\n",
    "hourly_snapshot_df = pd.DataFrame(hourly_snapshot_data)\n",
    "hourly_snapshot_df = hourly_snapshot_df.apply(pd.to_numeric, errors='coerce') \n",
    "hourly_snapshot_df.rename(columns = {'hourlyDepositUSD':'cumulativeDepositUSD', 'hourlyBorrowUSD':'cumulativeBorrowUSD', \"hourlyLiquidateUSD\": \"cumulativeLiquidateUSD\"}, inplace = True)\n",
    "hourly_snapshot_sums = hourly_snapshot_df.sum(axis=0) \n",
    "\n",
    "\n",
    "daily_snapshot_data = perform_pagenation_request(daily_snapshot_query, \"marketDailySnapshots\", query_variables)[\"marketDailySnapshots\"]\n",
    "daily_snapshot_df = pd.DataFrame(daily_snapshot_data)\n",
    "daily_snapshot_df = daily_snapshot_df.apply(pd.to_numeric, errors='coerce') \n",
    "daily_snapshot_df.rename(columns = {'dailyDepositUSD':'cumulativeDepositUSD', 'dailyBorrowUSD':'cumulativeBorrowUSD', \"dailyLiquidateUSD\": \"cumulativeLiquidateUSD\"}, inplace = True)\n",
    "daily_snapshot_sums = daily_snapshot_df.sum(axis=0) \n",
    "\n",
    "compare_df = pd.DataFrame({\"market_data\": filtered_market_data, \"hourly_snapshot_sums\": hourly_snapshot_sums, \"daily_snapshot_sums\": daily_snapshot_sums})\n",
    "compare_df[\"result\"] = np.where(list_items_match(compare_df[\"market_data\"], compare_df[\"hourly_snapshot_sums\"]) & list_items_match(compare_df[\"market_data\"], compare_df[\"daily_snapshot_sums\"]), PASS, FAIL)\n",
    "print(compare_df)\n",
    "\n",
    "result = PASS if (compare_df[\"result\"].to_numpy() == PASS).all() else FAIL\n",
    "check_summary[\"market_snapshots_check\"] = result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unique_user_check': 'PASS', 'protocol_cumulatives_match_check': 'PASS', 'financial_snapshots_check': 'FAIL', 'market_snapshots_check': 'PASS'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize results\n",
    "\n",
    "print(check_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a16afcfa13c3901ec800918c57279a94334b35ae1c71220f0a678463aca0e97a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
