{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "graph_id = \"QmX9Ucyfb6EMJC5ZeB61h1SuZ5HFKwJymA6We2xyzaQ1Tg\"\n",
    "url = f\"https://api.thegraph.com/subgraphs/id/{graph_id}\"\n",
    "\n",
    "\n",
    "PASS = \"PASS\"\n",
    "FAIL = \"FAIL\"\n",
    "MATCH_PERCENT_TOLERANCE = 0.00001 # Much be within 0.001% of eachother\n",
    "PAGE_LENGTH = 1000\n",
    "\n",
    "check_summary = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "def list_items_match(a: list, b: list) -> list:\n",
    "    exact_match = (a == b)\n",
    "    within_tolerance = abs(1 - a / b) < MATCH_PERCENT_TOLERANCE\n",
    "    return exact_match | within_tolerance \n",
    "    \n",
    "def perform_request(query, variables = {}):\n",
    "    res = requests.post(url, json={\"query\": query, \"variables\": variables})\n",
    "    return json.loads(res.text)[\"data\"]\n",
    "\n",
    "def perform_pagenation_request(pageable_query, key, varibales={}):\n",
    "    all_found = False\n",
    "    skip = 0\n",
    "    data = []\n",
    "\n",
    "    while(not all_found):\n",
    "        query_variables = varibales\n",
    "        query_variables[\"page_length\"] = PAGE_LENGTH\n",
    "        query_variables[\"skip\"] = skip\n",
    "\n",
    "        res = requests.post(url, json={\"query\": pageable_query, \"variables\": query_variables}) \n",
    "\n",
    "        new_data = json.loads(res.text)[\"data\"][key]\n",
    "        data += new_data\n",
    "\n",
    "        all_found = (len(new_data) != PAGE_LENGTH)\n",
    "        skip += PAGE_LENGTH\n",
    "    \n",
    "    return {key: data}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total accounts equals protocol account\n",
    "accounts_query = \"\"\"query($skip: Int!, $page_length: Int!) {\n",
    "    accounts(first: $page_length, skip: $skip) {\n",
    "        id\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "protocol_query = \"\"\"query {\n",
    "    protocols {\n",
    "        cumulativeUniqueUsers\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "account_data = perform_pagenation_request(accounts_query, \"accounts\")\n",
    "protocol_data = perform_request(protocol_query)\n",
    "num_accounts = len(account_data[\"accounts\"])\n",
    "cumulative_users = protocol_data[\"protocols\"][0][\"cumulativeUniqueUsers\"]\n",
    "\n",
    "result = PASS if num_accounts == cumulative_users else FAIL \n",
    "\n",
    "print(f\"num_accounts: {num_accounts}, cumulative_users: {cumulative_users}, result: {result}\")\n",
    "\n",
    "check_summary[\"unique_user_check\"] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   market_sums  protocol_cumulatives result\n",
      "totalValueLockedUSD               7.150305e+08          7.150305e+08   PASS\n",
      "cumulativeSupplySideRevenueUSD    3.911867e+07          3.911867e+07   PASS\n",
      "cumulativeProtocolSideRevenueUSD  9.794812e+07          9.794812e+07   PASS\n",
      "cumulativeTotalRevenueUSD         1.370668e+08          1.370668e+08   PASS\n",
      "totalDepositBalanceUSD            7.026939e+08          7.026939e+08   PASS\n",
      "cumulativeDepositUSD              1.186261e+09          1.186261e+09   PASS\n",
      "totalBorrowBalanceUSD             6.270124e+08          6.270124e+08   PASS\n",
      "cumulativeBorrowUSD               1.452832e+09          1.452832e+09   PASS\n",
      "cumulativeLiquidateUSD            0.000000e+00          0.000000e+00   PASS\n"
     ]
    }
   ],
   "source": [
    "# Check cumulative for protocol match sum for pools\n",
    "\n",
    "query = \"\"\"query {\n",
    "    lendingProtocols {\n",
    "        totalValueLockedUSD\n",
    "        cumulativeSupplySideRevenueUSD\n",
    "        cumulativeProtocolSideRevenueUSD\n",
    "        cumulativeTotalRevenueUSD\n",
    "        totalDepositBalanceUSD\n",
    "        cumulativeDepositUSD\n",
    "        totalBorrowBalanceUSD\n",
    "        cumulativeBorrowUSD\n",
    "        cumulativeLiquidateUSD\n",
    "    }\n",
    "    markets {\n",
    "        totalValueLockedUSD\n",
    "        cumulativeSupplySideRevenueUSD\n",
    "        cumulativeProtocolSideRevenueUSD\n",
    "        cumulativeTotalRevenueUSD\n",
    "        totalDepositBalanceUSD\n",
    "        cumulativeDepositUSD\n",
    "        totalBorrowBalanceUSD\n",
    "        cumulativeBorrowUSD\n",
    "        cumulativeLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "data = perform_request(query)\n",
    "protcol_data = data[\"lendingProtocols\"][0]\n",
    "market_data = data[\"markets\"]\n",
    "df = pd.DataFrame(market_data)\n",
    "df = df.apply(pd.to_numeric, errors='coerce') \n",
    "market_sums = df.sum(axis=0)\n",
    "\n",
    "compare_df = pd.DataFrame({\"market_sums\": market_sums, \"protocol_cumulatives\": protcol_data})\n",
    "compare_df = compare_df.apply(pd.to_numeric, errors='coerce') \n",
    "compare_df[\"result\"] = np.where(list_items_match(compare_df[\"market_sums\"], compare_df[\"protocol_cumulatives\"]), PASS, FAIL)\n",
    "print(compare_df)\n",
    "\n",
    "result = PASS if (compare_df[\"result\"].to_numpy() == PASS).all() else FAIL\n",
    "\n",
    "check_summary[\"protocol_cumulatives_match_check\"] = result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  snapshot_sums  protocol_cumulatives result\n",
      "cumulativeSupplySideRevenueUSD     3.911867e+07          3.911867e+07   PASS\n",
      "cumulativeProtocolSideRevenueUSD   9.794812e+07          9.794812e+07   PASS\n",
      "cumulativeDepositUSD               1.186261e+09          1.186261e+09   PASS\n",
      "cumulativeBorrowUSD                1.452832e+09          1.452832e+09   PASS\n",
      "cumulativeLiquidateUSD             0.000000e+00          0.000000e+00   PASS\n"
     ]
    }
   ],
   "source": [
    "# Check financial snapshots add up to protocol_cumulatives\n",
    "\n",
    "snapshot_query = \"\"\"query($skip: Int!, $page_length: Int!) {\n",
    "    financialsDailySnapshots(first: $page_length, skip: $skip) {\n",
    "        dailySupplySideRevenueUSD\n",
    "        dailyProtocolSideRevenueUSD\n",
    "        dailyDepositUSD\n",
    "        dailyBorrowUSD\n",
    "        dailyLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "protocol_query = \"\"\"query {\n",
    "    lendingProtocols {\n",
    "        cumulativeSupplySideRevenueUSD\n",
    "        cumulativeProtocolSideRevenueUSD\n",
    "        cumulativeDepositUSD\n",
    "        cumulativeBorrowUSD\n",
    "        cumulativeLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "protocol_data = perform_request(protocol_query)[\"lendingProtocols\"][0]\n",
    "snapshot_data = perform_pagenation_request(snapshot_query, \"financialsDailySnapshots\")[\"financialsDailySnapshots\"]\n",
    "df = pd.DataFrame(snapshot_data)\n",
    "df = df.apply(pd.to_numeric, errors='coerce') \n",
    "df.rename(columns = {'dailySupplySideRevenueUSD':'cumulativeSupplySideRevenueUSD', 'dailyProtocolSideRevenueUSD':'cumulativeProtocolSideRevenueUSD', \"dailyDepositUSD\": \"cumulativeDepositUSD\", \"dailyBorrowUSD\": \"cumulativeBorrowUSD\", \"dailyLiquidateUSD\": \"cumulativeLiquidateUSD\"}, inplace = True)\n",
    "sums = df.sum(axis=0)\n",
    "\n",
    "compare_df = pd.DataFrame({\"snapshot_sums\": sums, \"protocol_cumulatives\": protocol_data})\n",
    "compare_df = compare_df.apply(pd.to_numeric, errors='coerce') \n",
    "compare_df[\"result\"] = np.where(list_items_match(compare_df[\"snapshot_sums\"], compare_df[\"protocol_cumulatives\"]), PASS, FAIL)\n",
    "print(compare_df)\n",
    "\n",
    "result = PASS if (compare_df[\"result\"].to_numpy() == PASS).all() else FAIL\n",
    "\n",
    "check_summary[\"financial_snapshots_check\"] = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         market_data  hourly_snapshot_sums  \\\n",
      "cumulativeDepositUSD    5.010916e+07          5.010916e+07   \n",
      "cumulativeBorrowUSD     4.801522e+07          4.801522e+07   \n",
      "cumulativeLiquidateUSD  0.000000e+00          0.000000e+00   \n",
      "\n",
      "                        daily_snapshot_sums result  \n",
      "cumulativeDepositUSD           5.010916e+07   PASS  \n",
      "cumulativeBorrowUSD            4.801522e+07   PASS  \n",
      "cumulativeLiquidateUSD         0.000000e+00   PASS  \n"
     ]
    }
   ],
   "source": [
    "# Check market snapshots add up to market cumulatives\n",
    "\n",
    "market_query = \"\"\"query {\n",
    "    markets(first: 1) {\n",
    "        id\n",
    "        cumulativeDepositUSD\n",
    "        cumulativeBorrowUSD\n",
    "        cumulativeLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "hourly_snapshot_query = \"\"\"query($skip: Int!, $page_length: Int!, $market: String!) {\n",
    "    marketHourlySnapshots(first: $page_length, skip: $skip, where: {market: $market}) {\n",
    "        hourlyDepositUSD\n",
    "        hourlyBorrowUSD\n",
    "        hourlyLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "daily_snapshot_query = \"\"\"query($skip: Int!, $page_length: Int!, $market: String!) {\n",
    "    marketDailySnapshots(first: $page_length, skip: $skip, where: {market: $market}) {\n",
    "        dailyDepositUSD\n",
    "        dailyBorrowUSD\n",
    "        dailyLiquidateUSD\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "data = perform_request(query) \n",
    "market_data = perform_request(market_query)[\"markets\"][0]\n",
    "market_id = market_data[\"id\"]\n",
    "filtered_market_data = {\"cumulativeDepositUSD\": float(market_data[\"cumulativeDepositUSD\"]), \"cumulativeBorrowUSD\": float(market_data[\"cumulativeBorrowUSD\"]), \"cumulativeLiquidateUSD\": float(market_data[\"cumulativeLiquidateUSD\"])}\n",
    "\n",
    "query_variables = {\"market\": market_id}\n",
    "hourly_snapshot_data = perform_pagenation_request(hourly_snapshot_query, \"marketHourlySnapshots\", query_variables)[\"marketHourlySnapshots\"]\n",
    "hourly_snapshot_df = pd.DataFrame(hourly_snapshot_data)\n",
    "hourly_snapshot_df = hourly_snapshot_df.apply(pd.to_numeric, errors='coerce') \n",
    "hourly_snapshot_df.rename(columns = {'hourlyDepositUSD':'cumulativeDepositUSD', 'hourlyBorrowUSD':'cumulativeBorrowUSD', \"hourlyLiquidateUSD\": \"cumulativeLiquidateUSD\"}, inplace = True)\n",
    "hourly_snapshot_sums = hourly_snapshot_df.sum(axis=0) \n",
    "\n",
    "\n",
    "daily_snapshot_data = perform_pagenation_request(daily_snapshot_query, \"marketDailySnapshots\", query_variables)[\"marketDailySnapshots\"]\n",
    "daily_snapshot_df = pd.DataFrame(daily_snapshot_data)\n",
    "daily_snapshot_df = daily_snapshot_df.apply(pd.to_numeric, errors='coerce') \n",
    "daily_snapshot_df.rename(columns = {'dailyDepositUSD':'cumulativeDepositUSD', 'dailyBorrowUSD':'cumulativeBorrowUSD', \"dailyLiquidateUSD\": \"cumulativeLiquidateUSD\"}, inplace = True)\n",
    "daily_snapshot_sums = daily_snapshot_df.sum(axis=0) \n",
    "\n",
    "compare_df = pd.DataFrame({\"market_data\": filtered_market_data, \"hourly_snapshot_sums\": hourly_snapshot_sums, \"daily_snapshot_sums\": daily_snapshot_sums})\n",
    "compare_df[\"result\"] = np.where(list_items_match(compare_df[\"market_data\"], compare_df[\"hourly_snapshot_sums\"]) & list_items_match(compare_df[\"market_data\"], compare_df[\"daily_snapshot_sums\"]), PASS, FAIL)\n",
    "print(compare_df)\n",
    "\n",
    "result = PASS if (compare_df[\"result\"].to_numpy() == PASS).all() else FAIL\n",
    "check_summary[\"market_snapshots_check\"] = result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unique_user_check': 'PASS', 'protocol_cumulatives_match_check': 'PASS', 'financial_snapshots_check': 'PASS', 'market_snapshots_check': 'PASS'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize results\n",
    "\n",
    "print(check_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   inputToken  _cumulativeInterest  _cumulativePoolDelegateRevenue  \\\n",
      "0         NaN         1.290542e+20            16131780821917805622   \n",
      "1         NaN         1.151390e+20                               0   \n",
      "\n",
      "   _cumulativeTreasuryRevenue  _cumulativeDeposit  _cumulativeBorrow  \\\n",
      "0                1.222971e+21        1.932443e+22       1.860900e+22   \n",
      "1                9.723191e+20        1.480188e+22       1.479500e+22   \n",
      "\n",
      "   _cumulativeLiquidate  \n",
      "0                     0  \n",
      "1                     0  \n",
      "inputToken                        0.000000e+00\n",
      "_cumulativeInterest               2.441932e+20\n",
      "_cumulativePoolDelegateRevenue   -2.314963e+18\n",
      "_cumulativeTreasuryRevenue        2.195290e+21\n",
      "_cumulativeDeposit                3.412631e+22\n",
      "_cumulativeBorrow                 3.340400e+22\n",
      "_cumulativeLiquidate              0.000000e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "market_query = \"\"\"query {\n",
    "    markets{\n",
    "       inputToken {\n",
    "        name\n",
    "        }\n",
    "        _cumulativeInterest\n",
    "        _cumulativePoolDelegateRevenue\n",
    "        _cumulativeTreasuryRevenue\n",
    "\t\t_cumulativeDeposit\n",
    "        _cumulativeBorrow\n",
    "        _cumulativeLiquidate\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "data = perform_request(query) \n",
    "market_data = perform_request(market_query)[\"markets\"]\n",
    "\n",
    "usdc_market_data = [entry for entry in market_data if entry[\"inputToken\"][\"name\"] == \"USD Coin\"]\n",
    "eth_market_data = [entry for entry in market_data if entry[\"inputToken\"][\"name\"] == \"Wrapped Ether\"]\n",
    "\n",
    "usdc_market_df = pd.DataFrame(usdc_market_data)\n",
    "usdc_market_df = usdc_market_df.apply(pd.to_numeric, errors='coerce') \n",
    "\n",
    "eth_market_df = pd.DataFrame(eth_market_data)\n",
    "eth_market_df = eth_market_df.apply(pd.to_numeric, errors='coerce') \n",
    "eth_market_df\n",
    "\n",
    "usdc_market_sums = usdc_market_df.sum(axis=0) \n",
    "eth_market_sums = eth_market_df.sum(axis=0) \n",
    "print(eth_market_df)\n",
    "print(eth_market_sums)\n",
    "\n",
    "result = pd.concat([usdc_market_sums, eth_market_sums])\n",
    "\n",
    "\n",
    "# print(result)\n",
    "result.to_csv(\"exports/result.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a16afcfa13c3901ec800918c57279a94334b35ae1c71220f0a678463aca0e97a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
